---
title: " Modern Data Mining, HW 1"
author:
- Mahika Calyanakoti
- Graham Branscom
- Andrew Raine
date: 'Due: 11:59PM,  Feb 4th, 2024'
output:
  html_document:
    code_folding: show
    highlight: haddock
    number_sections: yes
    theme: lumen
    toc: yes
    toc_depth: 4
    toc_float: yes
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: '4'
  word_document:
    toc: yes
    toc_depth: '4'
urlcolor: blue
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, results = "hide", fig.width=8, fig.height=4)
options(scipen = 0, digits = 3)  # controls base R output
# check if you have ISLR package, if not, install it
if(!require('pacman')) {install.packages('pacman')}
pacman::p_load(ISLR, readxl, tidyverse, magrittr, dplyr, ggplot2)
```


\pagebreak

# Overview

This is a fast-paced course that covers a lot of material. There will be a large amount of references. You may need to do your own research to fill in the gaps in between lectures and homework/projects. It is impossible to learn data science without getting your hands dirty. Please budget your time evenly. Last-minute work ethic will not work for this course. 

Homework in this course is different from your usual homework assignment as a typical student. Most of the time, they are built over real case studies.  While you will be applying methods covered in lectures, you will also find that extra teaching materials appear here.  The focus will be always on the goals of the study, the usefulness of the data gathered, and the limitations in any conclusions you may draw. Always try to challenge your data analysis in a critical way. Frequently, there are no unique solutions. 

Case studies in each homework can be listed as your data science projects (e.g. on your CV) where you see fit. 



## Objectives 

- Get familiar with `R-studio` and `RMarkdown`
- Hands-on R 
- Learn data science essentials 
    - gather data
    - clean data
    - summarize data 
    - display data
    - conclusion
- Packages
    - `dplyr`
    - `ggplot`

##  Instructions

- **Homework assignments can be done in a group consisting of up to three members**. Please find your group members as soon as possible and register your group on our Canvas site.

- **All work submitted should be completed in the R Markdown format.** You can find a cheat sheet for R Markdown [here](https://www.rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf) For those who have never used it before, we urge you to start this homework as soon as possible. 

- **Submit the following files, one submission for each group:**  (1) Rmd file, (2) a compiled  HTML or pdf version, and (3) all necessary data files if different from our source data. You may directly edit this .rmd file to add your answers. If you intend to work on the problems separately within your group, compile your answers into one Rmd file before submitting. We encourage that you at least attempt each problem by yourself before working with your teammates. Additionally, ensure that you can 'knit' or compile your Rmd file. It is also likely that you need to configure Rstudio to properly convert files to PDF. [**These instructions**](http://kbroman.org/knitr_knutshell/pages/latex.html#converting-knitrlatex-to-pdf) might be helpful.

- In general, be as concise as possible while giving a fully complete answer to each question. All necessary datasets are available in this homework folder on Canvas. Make sure to document your code with comments (written on separate lines in a code chunk using a hashtag `#` before the comment) so the teaching fellows can follow along. R Markdown is particularly useful because it follows a 'stream of consciousness' approach: as you write code in a code chunk, make sure to explain what you are doing outside of the chunk. 

- A few good or solicited submissions will be used as sample solutions. When those are released, make sure to compare your answers and understand the solutions.


## Review materials

- Study Basic R Tutorial
- Study Advanced R Tutorial (to include `dplyr` and `ggplot`)
- Study lecture 1: Data Acquisition and EDA


# Case study 1: Audience Size

How successful is the Wharton Talk Show [Business Radio Powered by the Wharton School](https://businessradio.wharton.upenn.edu/)  


**Background:** Have you ever listened to [SiriusXM](https://www.siriusxm.com/)? Do you know there is a **Talk Show** run by Wharton professors in Sirius Radio?  Wharton launched a talk show called [Business Radio Powered by the Wharton School](https://businessradio.wharton.upenn.edu/) through the Sirius Radio station in January of 2014. Within a short period of time the general reaction seemed to be overwhelmingly positive. To find out the audience size for the show, we designed a survey and collected a data set via MTURK in May of 2014. Our goal was to **estimate the audience size**. There were 51.6 million Sirius Radio listeners then. One approach is to estimate the proportion of the Wharton listeners to that of the Sirius listeners, $p$, so that we will come up with an audience size estimate of approximately 51.6 million times $p$. 

To do so, we launched a survey via Amazon Mechanical Turk ([MTurk](https://www.mturk.com/)) on May 24, 2014 at an offered price of \$0.10 for each answered survey.  We set it to be run for 6 days with a target maximum sample size of 2000 as our goal. Most of the observations came in within the first two days. The main questions of interest are "Have you ever listened to Sirius Radio" and "Have you ever listened to Sirius Business Radio by Wharton?". A few demographic features used as control variables were also collected; these include Gender, Age and Household Income.  

We requested that only people in United States answer the questions. Each person can only fill in the questionnaire once to avoid duplicates. Aside from these restrictions, we opened the survey to everyone in MTurk with a hope that the sample would be more randomly chosen. 

The raw data is stored as `Survey_results_final.csv` on Canvas.

## Data preparation

1. We need to clean and select only the variables of interest. 

Select only the variables Age, Gender, Education Level, Household Income in 2013, Sirius Listener?, Wharton Listener? and Time used to finish the survey.

Change the variable names to be "age", "gender", "education", "income", "sirius", "wharton", "worktime".

```{r}
# loading the dataset and renaming selected columns
survey_data <- read_csv("./data/Survey_results_final.csv") %>% 
  select(
    age = Answer.Age,
    gender = Answer.Gender,
    education = Answer.Education,
    income = Answer.HouseHoldIncome,
    sirius = 'Answer.Sirius Radio',
    wharton = 'Answer.Wharton Radio',
    worktime = WorkTimeInSeconds
  )

# converting categorical variables to factors, and changing age to an integer
survey_data <- survey_data %>%
  mutate(
    age = as.integer(age),
    gender = as.factor(gender),
    education = as.factor(education),
    income = as.factor(income),
    sirius = as.factor(sirius),
    wharton = as.factor(wharton)
  )

head(survey_data)
```


2. Handle missing/wrongly filled values of the selected variables

As in real world data with user input, the data is incomplete, with missing values, and has incorrect responses. There is no general rule for dealing with these problems beyond “use common sense.” In whatever case, explain what the problems were and how you addressed them. Be sure to explain your rationale for your chosen methods of handling issues with the data. Do not use Excel for this, however tempting it might be.

Tip: Reflect on the reasons for which data could be wrong or missing. How would you address each case? For this homework, if you are trying to predict missing values with regression, you are definitely overthinking. Keep it simple.


### How we handled missing values.
We first filtered the dataset to see how many rows have at least one NA value. Since there are 1763 rows and only 20 problematic rows, a mere ~1% of all data, we opted to just drop them. In this case, it is not worth the challenge to predict missing values using regression.

```{r}
# filter for rows that contain at least one NA value
rows_with_na <- (survey_data[apply(survey_data, 1, function(x) any(is.na(x))),])
print(rows_with_na)
# drop the NA rows (~1% of total data)
survey_data <- na.omit(survey_data)
# check the na rows again
rows_with_na <- (survey_data[apply(survey_data, 1, function(x) any(is.na(x))),])
print(rows_with_na)

# filter for rows with age < 110
survey_data <- survey_data %>% filter(age < 110)
```


3. Brief summary 

Write a brief report to summarize all the variables collected. Include both summary statistics (including sample size) and graphical displays such as histograms or bar charts where appropriate. Comment on what you have found from this sample. (For example - it's very interesting to think about why would one work for a job that pays only 10cents/each survey? Who are those survey workers? The answer may be interesting even if it may not directly relate to our goal.)

```{r}
# a rough view of the dataset
cat("Data structure:\n")
survey_data %>% str()
# 1746 samples with 7 attributes
cat("\nData dimensions:\n")
dim(survey_data)
# summary statistics 
cat("\nData Summary:\n")
survey_data %>% summary()
```

```{r}
# Reordering the levels of the 'education' factor
survey_data$education <- factor(survey_data$education, levels = c(
  "Less than 12 years; no high school diploma",
  "High school graduate (or equivalent)",
  "Some college, no diploma; or Associate’s degree",
  "Bachelor’s degree or other 4-year degree",
  "Graduate or professional degree",
  "Other"
))
# Bar chart for Education
survey_data_filtered <- survey_data %>%
  filter(education != "select one")
ggplot(survey_data_filtered, aes(x = education, fill = gender)) +
  geom_bar(position = "dodge") +
  labs(title = "Education Level by Gender", x = "Education Level", y = "Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Bar chart for Income
# Reordering the levels of the 'income' factor
survey_data$income <- factor(survey_data$income, levels = c(
  "Less than $15,000",
  "$15,000 - $30,000",
  "$30,000 - $50,000",
  "$50,000 - $75,000",
  "$75,000 - $150,000",
  "Above $150,000"
))
ggplot(survey_data, aes(x = income, fill = gender)) +
  geom_bar(position = "dodge") +
  labs(title = "Income by Gender", x = "Income Level", y = "Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Bar chart for Sirius
ggplot(survey_data, aes(x = sirius, fill = gender)) +
  geom_bar(position = "dodge") +
  labs(title = "Sirius Listeners by Gender", x = "Sirius Listener", y = "Count") +
  theme_minimal()

# Bar chart for Wharton
ggplot(survey_data, aes(x = wharton, fill = gender)) +
  geom_bar(position = "dodge") +
  labs(title = "Wharton Listeners by Gender", x = "Wharton Listener", y = "Count") +
  theme_minimal()


# Creating a scatterplot of age against worktime, color-coded by gender and sized by income
ggplot(survey_data, aes(x = age, y = worktime, color = gender)) +
  geom_point() +
  labs(title = "Scatterplot of Age vs Worktime by Gender and Income",
       x = "Age",
       y = "Worktime") +
  theme_minimal()

#Education vs income
ggplot(survey_data, aes(x = education, fill = income)) +
  geom_bar(position = "dodge") +
  labs(title = "Income based on education", x = "Education level", y = "Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```


### Comments from visualizations
The education level follows roughly a normal distribution, where most respondents' education level was some college or a bachelor's degree. This pattern was the same across both genders.

The income level among females was moreso a normal distribution compared to that of the men. The females centered around \$30-50k, whereas the males plateaued from \$15-30k to \$75-150k. Thus, the men are more represented among the higher income brackets. The mode (i.e. most commonly chosen income bracket) was \$30-50k (424 respondents), which suggests that these survey workers were motivated by the 10 cent incentive because they have an income lower than the mean household income in the US.

Additionally, most respondents were Sirius listeners (\frac{1348}{1742}) and the majority of the Sirius listeners are men. Almost all respondents are not Wharton listeners (\frac{70}{1742}).

The age of listeners was concentrated around 20 to 40, and worktime was concentrated under 30 hours. These trends were similar across both genders. There are some notable outliers, like the 4 year-old respondent, a 76 year-old respondent and someone with a worktime of 108.

In our income vs education graph, as the education level increases, the median income level tends to shift from right to left (from lower to higher income).

## Sample properties

The population from which the sample is drawn determines where the results of our analysis can be applied or generalized. We include some basic demographic information for the purpose of identifying sample bias, if any exists. Combine our data and the general population distribution in age, gender and income to try to characterize our sample on hand.

1. Does this sample appear to be a random sample from the general population of the USA? Why it is crucial to have randomness here?

Overall, the data is not very representitive of the general US population.

Our data is majority male (1004 male, 738 female respondents), but the US population is roughly half male. Additionally, the median age is 28, but the median age in the US is 38 years-old. The most common income level is Bachelor's (612), which is representiative of about 33% of the US population whose highest education level is a Bachelor's. The most common income level is \$30-50k, which is about \$20-40k lower than the US average. The average worktime is 21.0 hours, which is considerably low considering a 9-5 workweek. The vast majority of respondents were Sirius listeners ($\frac{1348}{1742}), which is not representative for the overall US population. \\

It is crucial to have randomness here because if we want to use this survey to inform how the radio show markets to audiences or use this data to inform other radio shows, it is crucial to have data that mimics the overall US.

2. Does this sample appear to be a random sample from the MTURK population?

Overall, the sample does not appear to be a completely random sample of the MTURK population. The survey respondents are younger (median 28 years-old) than the MTURK population (median ~50-59 years-old). We have majority male (~58%), whereas MTURK is majority female (~58%). The MTURK population has a higher representation of higher income brackets compared to our data. For instance, two of the most common income brackets among the MTURK population is \$50-60k and \$100-150k.

We used the following link for MTURK population demographics data: (https://www.cloudresearch.com/resources/blog/who-uses-amazon-mturk-2020-demographics/).

Note: You can not provide evidence by simply looking at our data here. For example, you need to find distribution of education in our age group in US to see if the two groups match in distribution. You may need to gather some background information about the MTURK population to have a slight sense if this particular sample seem to a random sample from there... Please do not spend too much time gathering evidence. 

## Final estimate

Give a final estimate of the Wharton audience size by May of 2014. Assume that the sample is a random sample of the MTURK population, and that the proportion of Wharton listeners vs. Sirius listeners in the general population is the same as that in the MTURK population. Write a brief executive summary to summarize your findings and how you came to that conclusion.

To be specific, you should include:

###1. Goal of the study
The goal of the study is to estimate the audience size for Wharton Business Radio on the Sirius radio station using the results from an MTURK survey of under 2000 respondents in May 2014. We also aimed to collect demographic information about the survey respondents and see the relationship between the demographic variables.

###2. Method used: data gathering, estimation methods
We used an Amazon MTURK survey to gather data. We then used na.omit() to clean the data and then removed outliers. We also cleaned the data by converting to the factor data type to categorize the data. We made histograms and scatterplots to see the relationship between variables like education vs. income. We also used ggplot() and functions like summary() to visualize and summarize the data.

For estimation methods, we used proportional estimation to predict the total population. To estimate the total audience size in May 2014, we multiply the total number of Sirius Radio listeners (given to be 51.6 million) by $p$, where $p$ is the proportion of Wharton listeners to the total number of survey respondents. According to the data summary above, there are 1348 respondents who listen to Sirius (after filtering for NAs and outliers), only 70 of which said that they are Wharton listeners. Thus $p=\frac{70}{1348}$. So the total number of Wharton listeners equals 51.6 million times $\frac{1672}{1742}$, which is 2,679,525 Wharton listeners.

###3. Findings
We found based on the above calculations that the estimated number of Wharton radio listeners is 2,679,525. We also found that the sample was not completely representiative of the US population or the MTURK population. Based on the visualizations, we found that the education level follows roughly a normal distribution, and the income level among females was moreso a normal distribution compared to that of the men. The mode (i.e. most commonly chosen income bracket) was \$30-50k (424 respondents). Also, most respondents were Sirius listeners (\frac{1348}{1742}) and the majority of the Sirius listeners are men. Almost all respondents are not Wharton listeners (\frac{70}{1742}).

###4. Limitations of the study.

The main limitation of the study was that it was not representative of the US and MTURK populations. Additionally, the median age is 28, but the median age in the US is 38 years-old. For instance, we have majority male (~58%), whereas MTURK is majority female (~58%). Similar differences were seen for the other variables like education and income. This is a limitation because we want our survey data to be able to represent the overall populations so that we can better understand who the radio audience is.

The survey itself is also limited because it does not ask other information like how often they listen, how long they listen to shows, how long they have been listening to the radio, etc. The survey could also collect info on how the respondents would rate their experience listening to the Wharton Business Radio show and the radio in general.

## New task

Now suppose you are asked to design a study to estimate the audience size of Wharton Business Radio Show as of today: You are given a budget of $1000. You need to present your findings in two months. 

Write a proposal for this study which includes:

1. Method proposed to estimate the audience size.
2. What data should be collected and where it should be sourced from. (Can we use ChatGPT to get us a rough estimate?)

Please fill in the google form to list your platform where surveys will be launched and collected [HERE](https://forms.gle/8SmjFQ1tpqr6c4sa8) 


A good proposal will give an accurate estimation with the least amount of money used. 





# Case study 2: Women in Science


Are women underrepresented in science in general? How does gender relate to the type of educational degree pursued? Does the number of higher degrees increase over the years? In an attempt to answer these questions, we assembled a data set (`WomenData_06_16.xlsx`) from [NSF](https://ncses.nsf.gov/pubs/nsf19304/digest/field-of-degree-women) about various degrees granted in the U.S. from 2006 to 2016. It contains the following variables: Field (Non-science-engineering (`Non-S&E`) and sciences (`Computer sciences`, `Mathematics and statistics`, etc.)), Degree (`BS`, `MS`, `PhD`), Sex (`M`, `F`), Number of degrees granted, and Year.

Our goal is to answer the above questions only through EDA (Exploratory Data Analyses) without formal testing. We have provided sample R-codes in the appendix to help you if needed. 


## Data preparation  

1. Understand and clean the data

Notice the data came in as an Excel file. We need to use the package `readxl` and the function `read_excel()` to read the data `WomenData_06_16.xlsx` into R. 


a). Read the data into R.

b). Clean the names of each variables. (Change variable names to  `Field`,`Degree`, `Sex`, `Year` and `Number` )

c). Set the variable natures properly. 

d). Any missing values?

2. Write a summary describing the data set provided here. 

a). How many fields are there in this data?

b). What are the degree types? 

c). How many year's statistics are being reported here? 



## BS degrees in 2015

Is there evidence that more males are in science-related fields vs `Non-S&E`? Provide summary statistics and a plot which shows the number of people by gender and by field. Write a brief summary to describe your findings.

## EDA bringing type of degree, field and gender in 2015

Describe the number of people by type of degree, field, and gender. Do you see any evidence of gender effects over different types of degrees? Again, provide graphs to summarize your findings.

## EDA bring all variables 

In this last portion of the EDA, we ask you to provide evidence numerically and graphically: Do the number of  degrees change by gender, field, and time? 

## Women in Data Science

Finally, is there evidence showing that women are underrepresented in data science? Data science is an interdisciplinary field of computer science, math, and statistics. You may include year and/or degree.

## Final brief report

Summarize your findings focusing on answering the questions regarding if we see consistent patterns that more males pursue science-related fields. Any concerns with the data set? How could we improve on the study?

## Appendix

To help out, we have included some R-codes here as references. You should make your own chunks filled with texts going through each items listed above. Make sure to hide the unnecessary outputs/code etc. 

1. Clean data

```{r data wrangling, echo = FALSE, warning = FALSE}
# For the demonstration purpose, we show this R-chunk by taking echo=TRUE
# In your final report you should hide all the R-chunks to keep your report flowing well.
wsci <- read_excel("WomenData_06_16.xlsx")
names(wsci)
head(wsci)
#change names
wsci %<>% 
  rename(Field = 'Field and sex')
# set the field, degree and sex as factors
wsci %<>% 
  mutate( Field = as.factor(Field))
```


```{r, echo=FALSE}
# wsci %<>%
#   rename(Field = "Field and sex",
#          Number = "Degrees Awarded") %>%
#   mutate(Field = as.factor(Field),
#          Degree = as.factor(Degree),
#          Sex = as.factor(Sex))

```


2. A number of sample analyses 

```{r eval = FALSE, echo = FALSE}
wsci %>%  # to get the average number of ppl by gender
  group_by(Field, Sex) %>%
  summarise(deg = mean(Number))

wsci %>%
  filter(Year == 2007) %>%
  ggplot(aes(x = Field, y = Number, fill = Sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_grid(Degree~., scales = "free_y") +
  theme(axis.text.x = element_text(angle = 30, hjust = 1)) +
  ggtitle("Degrees granted across fields by degree and gender") 

wsci %>%
  mutate(SE = ifelse(Field!="Non-S&E" , "S&E", "Non-S&E")) %>%
  group_by(SE, Sex) %>%
  summarise(SE_number = sum(Number)) %>%
  ggplot(aes(x = SE, y = SE_number, fill = Sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme(axis.text.y = element_text(angle = 60)) +
  ggtitle("Degrees granted by S&E vs non-S&E by gender")

wsci %>%
  mutate(SE = ifelse(Field!="Non-S&E" , "S&E", "Non-S&E")) %>%
  group_by(SE, Sex, Year) %>%
  summarise(SE_number = sum(Number)) %>%
  group_by(SE, Year) %>%
  mutate(ratio = SE_number / sum(SE_number)) %>%
  filter(Sex == "Female") %>%
  ggplot(aes(x = Year, y = ratio, color = SE)) +
  geom_point() + geom_line() +
  ggtitle("Female proportion in SE/non-SE across year")

wsci %>%
  mutate(SE = ifelse(Field!="Non-S&E" , "S&E", "Non-S&E")) %>%
  group_by(SE, Sex, Year, Degree) %>%
  summarise(SE_number = sum(Number)) %>%
  group_by(SE, Year, Degree) %>%
  mutate(ratio = SE_number / sum(SE_number)) %>%
  filter(Sex == "Female") %>%
  ggplot(aes(x = Year, y = ratio, color = SE)) +
  geom_point() + geom_line() +
  facet_grid(~Degree)+
  ggtitle("Female proportion in SE/non-SE across year by degree")


wsci %>%
  mutate(SE = ifelse(Field!="Non-S&E" , "S&E", "Non-S&E")) %>%
  group_by(SE, Sex, Year, Degree) %>%
  summarise(SE_number = sum(Number)) %>%
  ggplot(aes(x = Year, y = SE_number, fill = Sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_grid(SE~Degree, scales = "free_y") +
  ggtitle("Degrees granted by sex, degree and SE")


wsci %>%
  mutate(SE = ifelse(Field!="Non-S&E" , "S&E", "Non-S&E")) %>%
  group_by(SE, Sex, Year, Degree) %>%
  summarise(SE_number = sum(Number)) %>%
  ggplot(aes(x = Year, y = SE_number, fill = Sex)) +
  geom_bar(stat = "identity", position = "fill") +
  facet_grid(SE~Degree, scales = "free_y") +
  ggtitle("Degrees granted proportion by sex across degree and SE")


wsci %>%
  filter(Field %in% c("Computer sciences", "Mathematics and statistics")) %>%
  ggplot(aes(x = Year, y = Number, fill = Sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_grid(Field~Degree, scales = "free_y") +
  ggtitle("Degrees granted pr option by sex across degree and SE")


wsci %>%
  ggplot(aes(x = Year, y = Number, fill = Sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_grid(Field~Degree, scales = "free_y") +
  ggtitle("Degrees granted proportion by sex across degree and SE")
```




# Case study 3: Major League Baseball

We would like to explore how payroll affects performance among Major League Baseball teams. The data is prepared in two formats record payroll, winning numbers/percentage by team from 1998 to 2014. 

Here are the datasets:

-`MLPayData_Total.csv`: wide format
-`baseball.csv`: long format

Feel free to use either dataset to address the problems. 

## EDA: Relationship between payroll changes and performance

Payroll may relate to performance among ML Baseball teams. One possible argument is that what affects this year's performance is not this year's payroll, but the amount that payroll increased from last year. Let us look into this through EDA. 

Create increment in payroll

a). To describe the increment of payroll in each year there are several possible approaches. Take 2013 as an example:

    - option 1: diff: payroll_2013 - payroll_2012
    - option 2: log diff: log(payroll_2013) - log(payroll_2012)

Explain why the log difference is more appropriate in this setup.

b). Create a new variable `diff_log=log(payroll_2013) - log(payroll_2012)`. Hint: use `dplyr::lag()` function.

c). Create a long data table including: team, year, diff_log, win_pct


## Exploratory questions

a). Which five teams had highest increase in their payroll between years 2010 and 2014, inclusive?

b). Between 2010 and 2014, inclusive, which team(s) "improved" the most? That is, had the biggest percentage gain in wins?


## Do log increases in payroll imply better performance? 

Is there evidence to support the hypothesis that higher increases in payroll on the log scale lead to increased performance?

Pick up a few statistics, accompanied with some data visualization, to support your answer. 

## Comparison

Which set of factors are better explaining performance? Yearly payroll or yearly increase in payroll? What criterion is being used? 






